# GithubClickhouseSaver

Скрипт для автоматического сбора топ Github репозиториев и сохранения
в Clickhouse базу данных.

## Установка и запуск

Необходимые зависимости могут быть установлены с помощью pip:

```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install -r requirements.txt
```

либо с помощью uv:

```bash
uv venv
source .venv/bin/activate
uv sync
```

Для использования скрипта в своих проектах, используйте класс 
`github_clickhouse_saver.saver.GithubClickhouseSaver`, который требует
на вход готовый `aiochclient.ChClient`.

```python
from github_clickhouse_saver.saver import GithubClickhouseSaver

...

github_token = "git_token..."

async with GithubClickhouseSaver(ch_client=ch_client) as github_saver:
    await github_saver.save_top_repos(
        access_token=github_token,
        limit=20,
    )
```

Для запуска скрипта напрямую, подготовьте файл `.env` в соответствии
с шаблоном `.env.example`, заполнив все необходимые данные. Они будут
использоваться для запуска скрипта.

После подготовки, достаточно вызвать скрипт командой:

```bash
python -m github_clickhouse_saver
```

Для установки параметров запуска, узнайте больше про аргументы командной строки:

```bash
python -m github_clickhouse_saver -h
```


## Важные детали реализации

### 1. GithubClickhouseSaver

`github_clickhouse_saver.saver.GithubClickhouseSaver`

Главный класс, отвечающий за выполнение скрипта по сохранению репозиториев,
полученных из Github API. Перед использованием должен быть инициализирован
с помощью метода `init()`. По умолчанию, класс не закрывает клиент подключения
при завершении (помогает, если скрипт является частью другого скрипта).
При желании, инициализирование и закрытие клиента можно автоматизировать
с помощью контекстного менеджера:

```python
async with GithubClickhouseSaver(ch_client) as saver:
    # Перед входом произошел вызов await saver.init()
    await saver.save_top_repos(access_token="...")
    # После выхода из менеджера ch_client будет автоматически закрыт.
    ...
```

### 2. Сохранение репозиториев в Clickhouse батчами

Одним из условиев задачи было эффективное использование оперативной 
памяти. Это значит, что подход с получением и хранением всех репозиториев
в оперативной памяти перед отправкой не подходит. Поэтому в классе
`GithubReposScrapper` был реализован метод `iter_repositories()`, позволяющий
проходить по репозиторям с эффективным использованием оперативной памяти.
При наполнении батча, создается таска для сохранения данных в БД, 
параллельно которой подготавливается следующий батч. Следующий батч
не будет отправлен, пока не закончится сохранение предыдущего.
Все это сделано для установления баланса "оперативная память" - "время выполнения".

Если опустить это условие, получение всех репозиториев
разом и отправка одним батчем могла бы быть быстрее. Либо параллельная
отправка нескольких меньших батчей, формируемых в процессе итерирования - 
тоже хорошая идея. Таким образом, можно было бы использовать уже реализованную
функцию `async_execute`, которая бы отправляла динамично сформированные
батчи в несколько потоков. Либо же можно было убрать ожидание выполнения
`current_save_task` перед созданием следующей, тогда таски по сохранению
создавались бы динамично с получением новых репозитриев. Но опять же,
это бы раздувало используемую оперативную память.

